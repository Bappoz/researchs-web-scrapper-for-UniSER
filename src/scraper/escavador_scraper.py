"""
ğŸ” SCRAPER DO ESCAVADOR
=======================
Scraper para buscar resumo do Lattes via Escavador
"""

import requests
from bs4 import BeautifulSoup
from typing import Dict, Any, Optional
import time
import random

class EscavadorScraper:
    """Scraper para buscar resumo do currÃ­culo Lattes via Escavador"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        })
    
    def search_profile_summary(self, name: str) -> Dict[str, Any]:
        """
        Busca o resumo do perfil Lattes via Escavador
        
        Args:
            name: Nome do pesquisador
            
        Returns:
            Dict com informaÃ§Ãµes do resumo do perfil
        """
        print(f"ğŸ” Buscando resumo do Lattes via Escavador para: {name}")
        
        try:
            # URL CORRETA do Escavador para buscar currÃ­culos Lattes
            search_url = "https://www.escavador.com/sobre"
            params = {
                'q': name
            }
            
            # Delay aleatÃ³rio para evitar bloqueio
            time.sleep(random.uniform(2, 4))
            
            # Fazer requisiÃ§Ã£o de busca
            print(f"ğŸ“¡ Acessando Escavador: {search_url}")
            response = self.session.get(search_url, params=params, timeout=20)
            
            print(f"ğŸ“Š Status Code: {response.status_code}")
            
            if response.status_code != 200:
                print(f"âš ï¸ Status code nÃ£o Ã© 200: {response.status_code}")
                return self._create_empty_result(name)
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # EstratÃ©gia: buscar elementos que contenham o nome e informaÃ§Ãµes acadÃªmicas
            # O Escavador geralmente mostra cards com informaÃ§Ãµes resumidas
            
            # Buscar qualquer menÃ§Ã£o ao currÃ­culo Lattes na pÃ¡gina
            page_text = soup.get_text()
            
            # Verificar se encontrou algo relacionado ao Lattes
            if 'lattes' in page_text.lower() or 'currÃ­culo' in page_text.lower():
                print("âœ… PÃ¡gina contÃ©m referÃªncia a Lattes/CurrÃ­culo")
                
                # Extrair informaÃ§Ãµes bÃ¡sicas
                summary_data = self._extract_from_page(soup, name)
                
                if summary_data.get('success'):
                    print(f"âœ… Resumo encontrado para: {summary_data.get('name', name)}")
                    return summary_data
            else:
                print("âš ï¸ Nenhuma referÃªncia a Lattes encontrada na pÃ¡gina")
            
            # Se nÃ£o encontrou nada, retornar resultado vazio
            return self._create_empty_result(name)
            
        except requests.exceptions.Timeout:
            print("âš ï¸ Timeout ao acessar Escavador")
            return self._create_empty_result(name)
        except Exception as e:
            print(f"âŒ Erro ao buscar no Escavador: {e}")
            import traceback
            traceback.print_exc()
            return self._create_empty_result(name)
    
    def _find_first_lattes_result(self, soup: BeautifulSoup) -> Optional[BeautifulSoup]:
        """Encontra o primeiro resultado de Lattes na pÃ¡gina"""
        try:
            # Procurar por diferentes possÃ­veis seletores do Escavador
            # (baseado em anÃ¡lise de pÃ¡ginas do Escavador)
            
            # Tentar encontrar cards de resultado
            result_cards = soup.find_all('div', class_=['resultado', 'card-resultado', 'resultado-pessoa'])
            
            for card in result_cards:
                # Verificar se Ã© resultado de Lattes
                text = card.get_text().lower()
                if 'lattes' in text or 'cnpq' in text or 'currÃ­culo' in text:
                    return card
            
            # Alternativa: procurar por links de Lattes
            lattes_links = soup.find_all('a', href=lambda x: x and 'lattes' in x.lower())
            if lattes_links:
                # Pegar o container pai do link
                return lattes_links[0].find_parent(['div', 'article', 'section'])
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ Erro ao procurar resultado: {e}")
            return None
    
    def _extract_from_page(self, soup: BeautifulSoup, original_name: str) -> Dict[str, Any]:
        """Extrai informaÃ§Ãµes gerais da pÃ¡gina inteira do Escavador"""
        try:
            page_text = soup.get_text(separator=' ', strip=True)
            
            # Buscar por padrÃµes comuns
            name = original_name
            summary = "InformaÃ§Ãµes disponÃ­veis no Escavador"
            institution = "NÃ£o especificada"
            area = "NÃ£o especificada"
            lattes_url = None
            
            # Tentar encontrar URL do Lattes
            lattes_links = soup.find_all('a', href=True)
            for link in lattes_links:
                href = link.get('href', '')
                if 'lattes.cnpq.br' in href or 'buscatextual.cnpq.br' in href:
                    lattes_url = href
                    break
            
            # Buscar por universidade no texto
            import re
            univ_match = re.search(r'(Universidade[^.,;\n]{0,80})', page_text, re.IGNORECASE)
            if univ_match:
                institution = univ_match.group(1).strip()
            
            # Se encontrou pelo menos a URL do Lattes, considerar sucesso
            if lattes_url:
                print(f"âœ… URL do Lattes encontrada: {lattes_url}")
                
                # Extrair um trecho relevante como resumo
                # Procurar por seÃ§Ãµes que contenham informaÃ§Ãµes acadÃªmicas
                academic_keywords = ['pesquisador', 'professor', 'doutor', 'mestre', 'graduaÃ§Ã£o', 'pÃ³s-graduaÃ§Ã£o', 'pesquisa']
                for keyword in academic_keywords:
                    if keyword in page_text.lower():
                        # Extrair contexto ao redor da palavra-chave
                        idx = page_text.lower().find(keyword)
                        start = max(0, idx - 100)
                        end = min(len(page_text), idx + 400)
                        summary = page_text[start:end].strip()
                        if len(summary) > 50:
                            break
                
                return {
                    "success": True,
                    "name": name,
                    "summary": summary,
                    "institution": institution,
                    "area": area,
                    "lattes_url": lattes_url,
                    "source": "escavador"
                }
            
            # Se nÃ£o encontrou URL mas tem menÃ§Ã£o a Lattes, retornar informaÃ§Ã£o bÃ¡sica
            if 'lattes' in page_text.lower():
                return {
                    "success": True,
                    "name": name,
                    "summary": "Perfil encontrado no Escavador com referÃªncia ao Lattes",
                    "institution": institution,
                    "area": area,
                    "lattes_url": None,
                    "source": "escavador"
                }
            
            return self._create_empty_result(original_name)
            
        except Exception as e:
            print(f"âš ï¸ Erro ao extrair da pÃ¡gina: {e}")
            import traceback
            traceback.print_exc()
            return self._create_empty_result(original_name)
    
    def _extract_summary_from_result(self, result_element: BeautifulSoup, original_name: str) -> Dict[str, Any]:
        """Extrai informaÃ§Ãµes do resumo do resultado"""
        try:
            # Extrair nome
            name = self._extract_name(result_element) or original_name
            
            # Extrair resumo/descriÃ§Ã£o
            summary = self._extract_summary_text(result_element)
            
            # Extrair instituiÃ§Ã£o
            institution = self._extract_institution(result_element)
            
            # Extrair Ã¡rea de atuaÃ§Ã£o
            area = self._extract_area(result_element)
            
            # Extrair link do Lattes (se disponÃ­vel)
            lattes_url = self._extract_lattes_url(result_element)
            
            return {
                "success": True,
                "name": name,
                "summary": summary,
                "institution": institution,
                "area": area,
                "lattes_url": lattes_url,
                "source": "escavador"
            }
            
        except Exception as e:
            print(f"âš ï¸ Erro ao extrair dados do resumo: {e}")
            return self._create_empty_result(original_name)
    
    def _extract_name(self, element: BeautifulSoup) -> Optional[str]:
        """Extrai o nome do pesquisador"""
        try:
            # Tentar diferentes seletores comuns
            name_selectors = [
                ('h2', {}),
                ('h3', {}),
                ('div', {'class': 'nome'}),
                ('span', {'class': 'nome'}),
                ('a', {'class': 'titulo'})
            ]
            
            for tag, attrs in name_selectors:
                name_elem = element.find(tag, attrs)
                if name_elem:
                    name = name_elem.get_text(strip=True)
                    if name and len(name) > 3:
                        return name
            
            return None
            
        except Exception:
            return None
    
    def _extract_summary_text(self, element: BeautifulSoup) -> str:
        """Extrai o texto do resumo"""
        try:
            # Procurar por elementos que contenham resumo/descriÃ§Ã£o
            summary_selectors = [
                ('div', {'class': ['resumo', 'descricao', 'texto']}),
                ('p', {'class': ['resumo', 'descricao']}),
                ('div', {'class': 'card-body'}),
            ]
            
            for tag, attrs in summary_selectors:
                summary_elem = element.find(tag, attrs)
                if summary_elem:
                    text = summary_elem.get_text(strip=True)
                    if text and len(text) > 20:
                        return text
            
            # Se nÃ£o encontrou, pegar todo o texto do elemento (limitado)
            all_text = element.get_text(separator=' ', strip=True)
            if all_text:
                # Limitar a 500 caracteres para nÃ£o pegar informaÃ§Ãµes demais
                return all_text[:500] + ('...' if len(all_text) > 500 else '')
            
            return "Resumo nÃ£o disponÃ­vel"
            
        except Exception:
            return "Resumo nÃ£o disponÃ­vel"
    
    def _extract_institution(self, element: BeautifulSoup) -> str:
        """Extrai a instituiÃ§Ã£o"""
        try:
            # Procurar por elementos de instituiÃ§Ã£o
            inst_selectors = [
                ('div', {'class': ['instituicao', 'afiliacao']}),
                ('span', {'class': ['instituicao', 'afiliacao']}),
            ]
            
            for tag, attrs in inst_selectors:
                inst_elem = element.find(tag, attrs)
                if inst_elem:
                    return inst_elem.get_text(strip=True)
            
            # Tentar encontrar no texto
            text = element.get_text()
            if 'Universidade' in text:
                # Extrair primeira ocorrÃªncia de universidade
                import re
                match = re.search(r'Universidade[^.;,\n]{0,100}', text)
                if match:
                    return match.group(0).strip()
            
            return "InstituiÃ§Ã£o nÃ£o informada"
            
        except Exception:
            return "InstituiÃ§Ã£o nÃ£o informada"
    
    def _extract_area(self, element: BeautifulSoup) -> str:
        """Extrai a Ã¡rea de atuaÃ§Ã£o"""
        try:
            # Procurar por elementos de Ã¡rea
            area_selectors = [
                ('div', {'class': ['area', 'especialidade']}),
                ('span', {'class': ['area', 'especialidade']}),
            ]
            
            for tag, attrs in area_selectors:
                area_elem = element.find(tag, attrs)
                if area_elem:
                    return area_elem.get_text(strip=True)
            
            return "Ãrea nÃ£o informada"
            
        except Exception:
            return "Ãrea nÃ£o informada"
    
    def _extract_lattes_url(self, element: BeautifulSoup) -> Optional[str]:
        """Extrai o URL do Lattes se disponÃ­vel"""
        try:
            # Procurar por links do Lattes
            links = element.find_all('a', href=True)
            
            for link in links:
                href = link.get('href', '')
                if 'lattes.cnpq.br' in href or 'buscatextual.cnpq.br' in href:
                    return href
            
            return None
            
        except Exception:
            return None
    
    def _create_empty_result(self, name: str) -> Dict[str, Any]:
        """Cria um resultado vazio quando nÃ£o hÃ¡ dados"""
        return {
            "success": False,
            "name": name,
            "summary": "Resumo nÃ£o encontrado no Escavador",
            "institution": "InstituiÃ§Ã£o nÃ£o informada",
            "area": "Ãrea nÃ£o informada",
            "lattes_url": None,
            "source": "escavador"
        }


# InstÃ¢ncia global para uso fÃ¡cil
escavador_scraper = EscavadorScraper()


# FunÃ§Ã£o de conveniÃªncia
def search_lattes_summary(name: str) -> Dict[str, Any]:
    """FunÃ§Ã£o de conveniÃªncia para buscar resumo do Lattes via Escavador"""
    return escavador_scraper.search_profile_summary(name)


if __name__ == "__main__":
    # Teste
    print("ğŸ§ª Testando Escavador Scraper")
    print("=" * 50)
    
    test_name = input("Digite o nome do pesquisador: ")
    result = search_lattes_summary(test_name)
    
    print("\nğŸ“Š Resultado:")
    print(f"Nome: {result.get('name')}")
    print(f"Resumo: {result.get('summary')}")
    print(f"InstituiÃ§Ã£o: {result.get('institution')}")
    print(f"Ãrea: {result.get('area')}")
    print(f"URL Lattes: {result.get('lattes_url')}")
